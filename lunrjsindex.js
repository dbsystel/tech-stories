var documents = [

{
    "id": 0,
    "uri": "search.html",
    "menu": "-",
    "title": "Search",
    "text": " lokale Suche https://codersblock.com/blog/mini-previews-for-links/ div#searchresults h3 { font-size: larger; margin-top: 0 !important; } div#searchresults h4 { font-size: large; } div#searchresults span { font-size: small; } div#searchresults span.menu { font-size: medium; margin-top: 1em; } function dosearch(element) { if (element.value.length>=3) { var searchresults = document.querySelector('#searchresults'); out = \"\"; var results = idx.search(element.value); if (results.length == 0) { results = idx.search(element.value+\"*\"); } if (results.length == 0) { results = idx.search(\"*\"+element.value+\"*\"); } if (results.length == 0) { results = idx.search(element.value+\"~1\"); } var lastMenu = \"\" var lastTitle = \"\" results.forEach(function (item) { var doc = documents[item.ref]; out += \" \"+doc.menu+\" \"; if (doc.menu != lastMenu) { lastMenu = doc.menu; } out += \" \" + doc.title + \" \"; for(var field in item.matchData.metadata) { console.log(field); var matches = item.matchData.metadata[field] if (matches['text']) { matches['text']['position'].forEach(function (pos) { var subtext = doc.text.substring(pos[0]-50,pos[0]+pos[1]+50); if (pos[0]>0) { subtext = subtext.replace(new RegExp(/^[^ ]*/,\"i\"),\"...\"); } subtext = subtext.replace(new RegExp(/[^ ]*$/,\"i\"),\"...\"); var re = new RegExp(field,\"gi\"); subtext = subtext.replace(re,\" $& \"); out += \" \" + subtext + \" \"; }) } } searchresults.innerHTML = out; }) } } var input = document.querySelector(\"#lunrsrc\"); input.focus(); var params = new URLSearchParams(window.location.search); input.value = params.get('q'); dosearch(input); "
},

{
    "id": 1,
    "uri": "blog/2023/2023-11-20-einfuehrung-barrierefreiheit-web.html",
    "menu": "Blog",
    "title": "A11y: EAA, BFSG, WCAG, WAI, ARIA, WTF? ‚Äì it's for the people stupid!",
    "text": " Table of Contents A11y: EAA, BFSG, WCAG, WAI, ARIA, WTF? ‚Äì it&#8217;s for the people stupid! Slides Referenzen A11y: EAA, BFSG, WCAG, WAI, ARIA, WTF? ‚Äì it&#8217;s for the people stupid! Barrierefreiheit ist ein verstaubtes und unwichtiges Thema f√ºr Beh√∂rdensoftware? Ganz im Gegenteil: Accessibility betrifft uns t√§glich und immer, wenn wir Software verwenden. Es ist an uns, diese umzusetzen. In unserem Talk von der W-JAX am 07.11.2023 zeigen wir euch, wie ihr eure Webanwendungen von Beginn an mit einfachen Mitteln zu einem hohen Grad barrierefrei gestaltet und entwickelt. Wir stellen euch effektive Methoden und Tools vor, die euch bei der Umsetzung und Pr√ºfung in hohem Ma√üe unterst√ºtzen. Wir gehen darauf ein, welchen Einfluss Barrierefreiheit auf eure Frontend-Architekturen hat und welche Aspekte hier zu beachten sind. Dabei beten wir nicht die einzelnen WCAG-Kriterien herunter ‚Äì vielmehr geben wir euch eine praktische Einf√ºhrung in das Thema Barrierefreiheit im Web und welche Kniffe und Fallstricke zu beachten sind. Slides Referenzen Bild von Bill Clinton W3C Logo Grafik \"human\" "
},

{
    "id": 2,
    "uri": "blog/2023/2023-11-20-conways-law.html",
    "menu": "Blog",
    "title": "Conway‚Äôs Law",
    "text": " Table of Contents Conway‚Äôs Law in real life - why organizational development and software engineering have to go hand in hand. Slides Conway‚Äôs Law in real life - why organizational development and software engineering have to go hand in hand. Conway‚Äôs Law inevitably connects the architecture of an software system with the responsible delivery organization. Unfortunately, persons responsible for organizational development and architects of software systems often work in separation ‚Äì especially in large enterprises. What are the negative effects of this separation and what can we do about it? In this talk Dr. Martin Strunk presents ‚Äúreal world examples‚Äù of the impact that arising from the ignorance of Conway`s law by decision makers. He will also propose ways, in which companies might overcome and mitigate these problems. Teams as first-class citizens Design comes first, then comes the participation Don‚Äôt rely on emergence to solve structural problems Slides "
},

{
    "id": 3,
    "uri": "blog/2023/2023-11-08-prompt-engineering.html",
    "menu": "Blog",
    "title": "Prompt-Engineering",
    "text": " Table of Contents Die faszinierende Welt des Prompt-Engineerings Slides Referenzen Die faszinierende Welt des Prompt-Engineerings Im Zentrum meines j√ºngsten Vortrags stand das Prompt-Engineering, ein Schl√ºsselelement im Umgang mit fortschrittlichen Sprachmodellen wie GPT-3 und GPT-4. Das Prompt-Engineering erm√∂glicht es Entwicklern, genaue und nuancierte Antworten von KI-Modellen zu erhalten und das Potenzial der KI voll auszusch√∂pfen. Wir tauchten tief in die Unterschiede zwischen GPT-3 und GPT-4 ein, erkundeten die Komplexit√§t neuronaler Netze und die Bedeutung der Multi-Modalit√§t in der heutigen KI-Landschaft. Ein besonderes Augenmerk legten wir auf die Kunst des Primings und der Kontextualisierung von Prompts, die die Effektivit√§t und Pr√§zision der KI-Interaktionen erheblich steigern k√∂nnen. Neben theoretischen √úberlegungen werden reale Anwendungsf√§lle diskutiert, die das Potenzial von Prompt-Engineering veranschaulichen. Slides Referenzen Golem.de: BSI sieht KI als Sicherhitsrisiko Twitter: The Hired AI Medium: ChatGPT Architecture Explained by Sreedev R Scientific Reports: Comparative performance of humans versus GPT-4.0 and GPT-3.5 GPT-4: Wikipedia FAZ.net: ChatGPT: Welche Einstellungen bei der Nutzung helfen OpenAI Chat: Beispiel OpenAI: Verbesserung der docToolchain Dokumentation DeepLearning.AI: ChatGPT Prompt Engineering for Developers Heise Online: Softwarearchitektur: \"KI wird unsere F√§higkeiten erg√§nzen, nicht ersetzen\" Heise Online: KI in der Softwareentwicklung: √úbersch√§tzt OpenAI Chat: Beispiel 2 Stefan Toth: Architektur in Zeiten von KI und LLMs "
},

{
    "id": 4,
    "uri": "blog/2023/2023-08-21-vue2-vue3-migration.html",
    "menu": "Blog",
    "title": "Migrate Vue 2 to Vue 3",
    "text": " Table of Contents How we migrated our Vue 2 enterprise project to Vue 3 About me and my Team Where we started Preparations Migrations before the migration Finally: Migrate to Vue 3 Post-Migration-Steps Conclusion How we migrated our Vue 2 enterprise project to Vue 3 About me and my Team Where we started Preparations Migrations before the migration Finally: Migrate to Vue 3 Post-Migration-Steps Conclusion How we migrated our Vue 2 enterprise project to Vue 3 It&#8217;s been a while: Since the 2nd February 2022, Vue 3 became the new default for Vue.js apps. It&#8217;s done! Vue 3 is now the default version and the brand new http://vuejs.org is live! More details in the blog post in case you missed it: https://blog.vuejs.org/posts/vue-3-as-the-new-default.html Tweet from @vuejs on Twitter It was a long journey to the final default release of Vue 3 since the first version published on 18th September 2020. But: even if Vue 3 isn&#8217;t a new thing anymore, there are still a lot of Vue 2 apps which haven&#8217;t been migrated yet. The migration can be quite heavy since in practice it&#8217;s much more than only following the migration guide. Projects usually rely also on 3rd-party dependencies which are maybe not available for Vue 3 or not maintained anymore. In this blog post I will give you an insight into how my team mastered the migration and what pitfalls we faced. I will describe how we planned and migrated our whole Vue 2 codebase to Vue 3 using Pinia as Store-Solution, Vite for our build environment and Vitest for fast unit test executions. The focus of this article is not to provide a very detailed step-by-step migration guide. I will focus about what things you should keep in mind, what you can already do before starting the migration and about some pitfalls we pointed out. However, I will provide you links to more detailed blog posts about specific topics. Please keep in mind, that the way we solved the migration won&#8217;t probably fit to your very specific setup for 100%, but you can check what parts seem to be good for you and your team. Vue 2 EOL: Please note, that the Vue 2 support will end on December 31st, 2023. This means there will be no fixes and features provided anymore (unless you are actively extending the support ) About me and my Team To give you a high level overview about our context, I would just like to say a few short words about myself and my team. I am working at DB Systel GmbH , in a DevOps Team building a Business-to-Government (B2G) solution together with our partner Deutsche Bahn Connect GmbH named DB Curbside Management . Our product focuses on helping cities and councils to effectively manage shared mobility offerings and their jurisdictions dynamically. They will be able to get insights about statistics, violations of agreements with the mobility providers to regulate a fair and steady distribution of all the different shared mobility vehicles across managed area. Where we started My team added the migration to Vue 3 with the new default setup and tools using Vite , Pinia and Vitest to our backlog many months ago, but the switch to Vue 3 as default gave us another push for facing the migration. We realized pretty fast, that a big-bang migration wouldn&#8217;t be possible for us, since it will block us releasing new features for quite a long time. Our codebase contained already ~200 Vue 2 components using the old-fashioned Options API as well as a huge Vuex Store and some libraries that aren&#8217;t compatible with Vue 3. Preparations Let&#8217;s start with the preparation of your team and questions you should answer yourself before starting the migration. The first thing you should do is to get comfy with Vue 3, and you should learn about the differences compared to Vue 2 and the options you have. You can set up a Vue 3 playground app locally and explore yourself the new setup and components. To know what things will change when starting the migration, I would recommend you the read the following articles in advance: Official Vue 2 to Vue 3 Migration Guide Blogpost: \"Vue.js: How to Migrate a large project from Vue 2 to Vue 3\" from Baptiste Jamin Official Vue 3 notes about the Composition API and the relationship / differences compared to the Options API Vue Master Blog-Series by Andy Li Part 1 | Part 2 Free Vue Mastery Video Course \"From Vue 2 to Vue 3\" Update to the latest minor Vue 2 version My first advice is to keep your current app as up-to-date as possible. Especially when your Vue version is below 2.7.x , I would recommend you to update it. With Vue 2.7.x \"Naruto\" release, the Vue team aimed to backport lots of features from Vue 3 to Vue 2 without introducing a breaking change. This will help you to migrate some things in preparation for a smooth Vue 3 switch. Check out the official announcement and start migrating to the Vue 3 flavour in your Vue 2 app: TypeScript or not? Are you using TypeScript right now or do you plan to migrate to TypeScript? In that case you should read the TypeScript Notes for Vue 3 . Generally I would highly recommend to use TypeScript as the Vue 2 and Vue 3 TypeScript integration is great. It will help you a lot to reduce runtime errors as hard debugging nights by analyzing bugs in production. Be prepared, that switching to Typescript might require quite an effort, but it&#8217;s still worth it. Check your dependencies A big thing you definitely have to check before is: dependencies. You should check if you are using packages that will rely on Vue 2 and won&#8217;t be available for Vue 3. Such dependencies will require your attention as they may block you from updating to Vue 3. In my previous project we weren&#8217;t able to update to Vue 3 a long time since we had a dependency to BootstrapVue which wasn&#8217;t working with Vue 3 and isn&#8217;t still. In such case where a package isn&#8217;t compatible you have the following options: Check if there is an equivalent package or a fork of your dependency that will support Vue 3. If there is one: be sure it&#8217;s still maintained and alive. If the package is just a Vue-wrapper for a common library, you may need to use the library directly Find a similar package that supports Vue 3. In this case you have to make sure the new dependency supports all your use-cases, and you have to plan how to migrate this dependency. You can contribute to the dependency and help to make it Vue 3 compatible. You may have to check VueDemi which is a great developing utility to create or update Universal Vue Libraries for Vue 2 &amp; 3. Worst Case: Write the features you need by yourself, but be sure to open-source it afterwards ;-) In all these cases you should make yourself a list of the relevant development tasks with a very rough estimate about how complex the migration will be. For example write a + if the dependency migration is straight forward (already Vue 3 compatible). Write + for very hard-to-migrate dependencies, where you may need another solution or lib or implement stuff by yourself. Add Notes about things you shouldn&#8217;t forget when starting the migration. You should also include development dependencies for example for webpack plugins. It could look like the following example: Vue 2 dependency Vue 3 dependency notes estimate @dsb-norge/vue-keycloak-js @baloise/vue-keycloak similar API, similar features ++ v-tooltip floating-vue same lib under the hood with more features + vue2-datepicker vue-datepicker-next same lib with Vue 3 support + vue2-leaflet @vue-leaflet/vue-leaflet same API, but lots of relying components ++ vue2-leaflet-draw-toolbar - no Vue 3 equivalent + webpack-license-plugin rollup-plugin-license different plugin for rollup, with a different API, we need to check / adjust the output format + Try out things in a playground For dependency update / migrations you can&#8217;t estimate, it&#8217;s a good idea to set them up / try them out in an isolated new Vue 3 playground environment. After playing around, you should be able to estimate the effort. A good example when having a look at the migration list above would be to try out the rollup-plugin-license package. Check your current Webpack environment When coming from webpack and planning to migrate to Vite, you should check your webpack config for any special behaviors. You can use the playground to reflect / try out the setup in Vite. Here are some points that were interesting for us: We don&#8217;t need a specific SCSS/SASS/LESS configuration anymore as Vite brings support for this out-of-the-box We needed to migrate the webpack-license-plugin to rollup-plugin-license (see above) Vite comes with its own approach of reading and passing environment variables and build modes which is quite easy and handy Static Asset Handling by Vite is something you should probably know before Split your Store on paper When currently using Vuex, you may be lucky, and you have already some modules splitting your store into logical parts. In our case we had just one big store without any modules as the codebase has evolved over time, and we haven&#8217;t made the step to split the store. The migration to Pinia can be a good chance to face this now as Pinia lets you easily compose multiple small stores. You should check your current store configuration and write down the modules that are loosely coupled or even completely independent (e.g. a user or an auth store). Make the migration transparent and estimable The last thing we have done was to create a new epic for the whole migration and to create small estimable tasks. This was very important as we were now able to identify things we can prepare and do even before we started the migration itself and also tasks we can do in advance. On the other hand it helped us for the communication with the product owner and to make things transparent. Please keep in mind to add some time buffer for unexpected things occurring during the migration where you may need some extra time. For example: the migration from Vuex to Pinia took a lot more time than we thought before. But: it was definitely worth it. The TypeScript support is way better and the unification of actions and mutations reduces the Boilerplate code a lot. We also underestimated the time we needed to migrate the tests. This was hard by definition but quite time-consuming as I wrote in the introduction: We had a huge Vuex store. Migrations before the migration Before starting the migration itself you should migrate everything you can, which is not related to Vue 3 / vite. Here is what we have done in my team before the migration itself. Convert Filters to functions Vue 3 kicked out the concept of using filters in the template using the pipe ( | ) syntax ( {{ expression | myFilter }} ). Filters are simply functions that can be imported and used directly. You can already import the functions, use them as a method and then pass through the expression in the template before starting the Vu3 migration: {{ myFilter(expression) }} . Update and migrate dependencies Update all possible dependencies to their latest versions to make migrations for other libs in advance. At this step: double-check if vue-specific libs are ready for using with Vue 3 or if there are other libs you have to use. If you have to change to other libs and this one supports Vue 3, make the migration now. In our team we had already lots of our dependencies updated, since we are using Mend (formerly Whitesource) Renovate for housekeeping and continuous dependency version updates. When you decide to migrate a dependency to a new one that supports Vue 2 and Vue 3 or which should be replaced with a self-implementation: Do it in advance before the actual Vue migration. Isolate hard-to-migrate components It may happens, you realize, for some of your dependencies a migration won&#8217;t be straight-forward. In our case we decided some years ago, we want to use Leaflet.js as our map library to display and interact with features on a map. Therefore we also used a wrapper for Vue 2 applications called Vue2Leaflet which made us use Leaflet in a declarative manner. However, this architectural decision was now a problem for us, as not only this dependency is not supposed to use it with Vue 3 but also extensions for this library such as Leaflet.heat needed to be migrated. To face this issue we&#8217;ve gone one step back and rethink our architectural decision to use Leaflet. At this time there was already a Vue 3 wrapper for leaflet available but not as feature-rich as we needed it. So we created a new Architectural Decision Record (ADR) to evaluate and choose our future map library as it is a central component of our app and can&#8217;t be easily replaced. After doing a Proof-of-Concept (PoC), we decided to switch to OpenLayers and make use of the vue3-openlayers wrapper too, where we were also able to contribute missing features back into the project. This whole story is probably quite special to my team and our app, but the essential thing here was, that we prepared the central components in parallel to our productive app in a separate repository in isolation. Therefore, we created the components and defined their props and events with the help of Storybook . Of course, we also created tests for these components, so that we were prepared to copy over all this into the productive app and replace the existing components later, when we were ready to actually migrate to Vue 3. A drawback with this approach is of course: It probably blocks you with releasing new features or you have to implement them twice during the preparation time (one time for the productive app based on Vue 2, one time for the isolated components based on Vue 3). Update your NPM Scripts When checking your Vue 3 default setup you will notice that some NPM script names have changed by default. For example the default command to run the development build and server is now npm run dev instead of npm run serve . You can either change the names back since you are used to the \"old\" commands, or you can already name your commands in the Vue 2 setup to the new ones to get comfy with it. Please note that you may have to change the commands in you CI/CD Pipeline too. Switch to Vite You can switch to Vite before updating to Vue 3 this makes the \"big bang\" migration a bit smaller. For that, you should install Vite and use the official plugin @vitejs/plugin-vue2 . You also need to migrate all the webpack plugins and configs. When the setup is finished, cleanup all the webpack stuff including the config and the dependencies. During the migration we noticed, that we haven&#8217;t used Type-Only Imports in all our typescript and .vue files. The default Vite setup is configured in such way, Type-Only Imports will be forced when needed, otherwise you&#8217;ll receive errors during the build. We had the option to either deactivate this strict behavior by setting the typescript config option importsNotUsedAsValues to either preserve or remove (not recommended) or to migrate. Luckily, there is a community project called ts-import-types-cli that will automate a part of this step. So we just had to run the following command to migrate to Type-Only Imports at places needed: # remove the `--dry-run` flag to migrate actually and not only list the changes npx ts-import-types-cli --no-organise-imports -p tsconfig.json --dry-run The bad news: The tool didn&#8217;t find all occurrences of the Type-Only Imports, so when running npm run build , we caught some more we had to fix manually. Switch to Vitest After your migration to Vite, you should make use of Vitest as your new pretty and fast unit testing framework. In comparison to Jest it comes with a stable out-of-the-box ESM support and faster test executions. Until now Jest&#8217;s support for ESM is still experimental (State: Jest Version 29.5). The API is quite similar and mostly compatible to jest . If you used Mocha before, the migration shouldn&#8217;t be hard either. Switch to Pinia The next big step you should do in advance is the migration of your Vuex store. You can also do this step after the migration itself and keep Vuex for now. However, we decided, it&#8217;s a good idea, to migrate the store before and switch to Pinia since the API is a lot simpler and better composable when slicing our big store into chunks. Furthermore, it comes with better TypeScript support. At the Pinia-Docs you will find a very detailed Guide for the Migration from Vuex Migrate Components Last but not least we decided to migrate all our components to the composition API with the &lt;script setup&gt; syntactical sugar . This is a step you can also omit or do in advance, but we recommend using this API since it&#8217;s also a bit more performant, and it reduces the boilerplate code you have to write. Finally: Migrate to Vue 3 You are now prepared to migrate to Vue 3, and you&#8217;ve done already a lot of things which made this step much easier and shorter. Now you can start the migration of Vue itself. Keep in mind, that for the actual migration you must migrate the unit tests too as the test utils for vue3 are slightly different. Migrate the source code Here we started by adding Vue 3 as well as the @vue/compat package as described in the Vue 3 Migration Build documentation . Also, we needed to update the VueRouter to version 4.x.x and adjust the configuration. As good step-by-step guides, I would recommend you again to read the following Blogposts: \"Vue.js: How to Migrate a large project from Vue 2 to Vue 3\" from Baptiste Jamin The official Vue 2 to Vue 3 Migration Guide . If you have already prepared some components in isolation to work with Vue 3 as we did: Of course you should replace the old ones and probably adjust the props or events if the API of your new components changed compared to the Vue 2 ones. After this step your whole app should work as before (fingers crossed). The migration of the components itself can be done one by one after the migration until everything is converted to Vue 3. Migrate to @vue/test-utils@v2 After you migrated everything, you need to update to @vue/test-utils@v2 . The migration should be straight-forward when following the migration guide . Nonetheless it can take quite a bit of time depending on the amount of unit tests you have. Post-Migration-Steps Remove Compatibility Package Once every component is migrated, make sure to remove the @vue/compat and it&#8217;s configuration as you don&#8217;t need it anymore. Make use of the Teleport feature Now that we are using Vue 3, we can use the \"Teleport\" feature. Think about components creating their DOM elements deeply in the DOM caused by the component hierarchy but where you would expect the elements to appear somewhere else close to the root. A good example is displaying a modal conditionally: &lt;body&gt; &lt;ComponentOne&gt; &lt;ComponentTwo&gt; &lt;ComponentThree&gt; &lt;MyModal v-if=\"myCondition\"&gt; &lt;/ComponentThree&gt; &lt;/ComponentTwo&gt; &lt;/ComponentOne&gt; &lt;/body&gt; In Vue 2, the modal would be rendered and appear inside the ComponentThree . Using teleport in MyModal can lift the element up to the body tag which makes more sense for common modal dialogs. Conclusion Migrating from Vue 2 to Vue 3 can be a huge thing and takes quite a bit of time. But good preparation and pre-migration will make the whole migration process much easier, more estimable and won&#8217;t block you for so long with releasing new features. Compared to writing the whole thing from scratch, we think this was well worth it. I hope this post gave you some inspiration of how you can face the migration of your project. Happy Migration ‚úåüèº :jbake-title: Migrate Vue 2 to Vue 3 :jbake-card: How we migrated our Vue 2 enterprise project to Vue 3 :jbake-date: 2023-08-21 :jbake-type: post :jbake-tags: javascript, vue :jbake-status: published :jbake-menu: Blog :jbake-discussion: 1076 :jbake-author: Danny Koppenhagen :jbake-teaser-image: profiles/Danny-Koppenhagen.png :jbake-tags: javascript, vue How we migrated our Vue 2 enterprise project to Vue 3 It&#8217;s been a while: Since the 2nd February 2022, Vue 3 became the new default for Vue.js apps. It&#8217;s done! Vue 3 is now the default version and the brand new http://vuejs.org is live! More details in the blog post in case you missed it: https://blog.vuejs.org/posts/vue-3-as-the-new-default.html Tweet from @vuejs on Twitter It was a long journey to the final default release of Vue 3 since the first version published on 18th September 2020. But: even if Vue 3 isn&#8217;t a new thing anymore, there are still a lot of Vue 2 apps which haven&#8217;t been migrated yet. The migration can be quite heavy since in practice it&#8217;s much more than only following the migration guide. Projects usually rely also on 3rd-party dependencies which are maybe not available for Vue 3 or not maintained anymore. In this blog post I will give you an insight into how my team mastered the migration and what pitfalls we faced. I will describe how we planned and migrated our whole Vue 2 codebase to Vue 3 using Pinia as Store-Solution, Vite for our build environment and Vitest for fast unit test executions. The focus of this article is not to provide a very detailed step-by-step migration guide. I will focus about what things you should keep in mind, what you can already do before starting the migration and about some pitfalls we pointed out. However, I will provide you links to more detailed blog posts about specific topics. Please keep in mind, that the way we solved the migration won&#8217;t probably fit to your very specific setup for 100%, but you can check what parts seem to be good for you and your team. Vue 2 EOL: Please note, that the Vue 2 support will end on December 31st, 2023. This means there will be no fixes and features provided anymore (unless you are actively extending the support ) About me and my Team To give you a high level overview about our context, I would just like to say a few short words about myself and my team. I am working at DB Systel GmbH , in a DevOps Team building a Business-to-Government (B2G) solution together with our partner Deutsche Bahn Connect GmbH named DB Curbside Management . Our product focuses on helping cities and councils to effectively manage shared mobility offerings and their jurisdictions dynamically. They will be able to get insights about statistics, violations of agreements with the mobility providers to regulate a fair and steady distribution of all the different shared mobility vehicles across managed area. Where we started My team added the migration to Vue 3 with the new default setup and tools using Vite , Pinia and Vitest to our backlog many months ago, but the switch to Vue 3 as default gave us another push for facing the migration. We realized pretty fast, that a big-bang migration wouldn&#8217;t be possible for us, since it will block us releasing new features for quite a long time. Our codebase contained already ~200 Vue 2 components using the old-fashioned Options API as well as a huge Vuex Store and some libraries that aren&#8217;t compatible with Vue 3. Preparations Let&#8217;s start with the preparation of your team and questions you should answer yourself before starting the migration. The first thing you should do is to get comfy with Vue 3, and you should learn about the differences compared to Vue 2 and the options you have. You can set up a Vue 3 playground app locally and explore yourself the new setup and components. To know what things will change when starting the migration, I would recommend you the read the following articles in advance: Official Vue 2 to Vue 3 Migration Guide Blogpost: \"Vue.js: How to Migrate a large project from Vue 2 to Vue 3\" from Baptiste Jamin Official Vue 3 notes about the Composition API and the relationship / differences compared to the Options API Vue Master Blog-Series by Andy Li Part 1 | Part 2 Free Vue Mastery Video Course \"From Vue 2 to Vue 3\" Update to the latest minor Vue 2 version My first advice is to keep your current app as up-to-date as possible. Especially when your Vue version is below 2.7.x , I would recommend you to update it. With Vue 2.7.x \"Naruto\" release, the Vue team aimed to backport lots of features from Vue 3 to Vue 2 without introducing a breaking change. This will help you to migrate some things in preparation for a smooth Vue 3 switch. Check out the official announcement and start migrating to the Vue 3 flavour in your Vue 2 app: TypeScript or not? Are you using TypeScript right now or do you plan to migrate to TypeScript? In that case you should read the TypeScript Notes for Vue 3 . Generally I would highly recommend to use TypeScript as the Vue 2 and Vue 3 TypeScript integration is great. It will help you a lot to reduce runtime errors as hard debugging nights by analyzing bugs in production. Be prepared, that switching to Typescript might require quite an effort, but it&#8217;s still worth it. Check your dependencies A big thing you definitely have to check before is: dependencies. You should check if you are using packages that will rely on Vue 2 and won&#8217;t be available for Vue 3. Such dependencies will require your attention as they may block you from updating to Vue 3. In my previous project we weren&#8217;t able to update to Vue 3 a long time since we had a dependency to BootstrapVue which wasn&#8217;t working with Vue 3 and isn&#8217;t still. In such case where a package isn&#8217;t compatible you have the following options: Check if there is an equivalent package or a fork of your dependency that will support Vue 3. If there is one: be sure it&#8217;s still maintained and alive. If the package is just a Vue-wrapper for a common library, you may need to use the library directly Find a similar package that supports Vue 3. In this case you have to make sure the new dependency supports all your use-cases, and you have to plan how to migrate this dependency. You can contribute to the dependency and help to make it Vue 3 compatible. You may have to check VueDemi which is a great developing utility to create or update Universal Vue Libraries for Vue 2 &amp; 3. Worst Case: Write the features you need by yourself, but be sure to open-source it afterwards ;-) In all these cases you should make yourself a list of the relevant development tasks with a very rough estimate about how complex the migration will be. For example write a + if the dependency migration is straight forward (already Vue 3 compatible). Write + for very hard-to-migrate dependencies, where you may need another solution or lib or implement stuff by yourself. Add Notes about things you shouldn&#8217;t forget when starting the migration. You should also include development dependencies for example for webpack plugins. It could look like the following example: Vue 2 dependency Vue 3 dependency notes estimate @dsb-norge/vue-keycloak-js @baloise/vue-keycloak similar API, similar features ++ v-tooltip floating-vue same lib under the hood with more features + vue2-datepicker vue-datepicker-next same lib with Vue 3 support + vue2-leaflet @vue-leaflet/vue-leaflet same API, but lots of relying components ++ | vue2-leaflet-draw-toolbar | - | no Vue 3 equivalent | ++ | | webpack-license-plugin | rollup-plugin-license | different plugin for rollup, with a different API, we need to check / adjust the output format | | Try out things in a playground For dependency update / migrations you can&#8217;t estimate, it&#8217;s a good idea to set them up / try them out in an isolated new Vue 3 playground environment. After playing around, you should be able to estimate the effort. A good example when having a look at the migration list above would be to try out the rollup-plugin-license package. Check your current Webpack environment When coming from webpack and planning to migrate to Vite, you should check your webpack config for any special behaviors. You can use the playground to reflect / try out the setup in Vite. Here are some points that were interesting for us: We don&#8217;t need a specific SCSS/SASS/LESS configuration anymore as Vite brings support for this out-of-the-box We needed to migrate the webpack-license-plugin to rollup-plugin-license (see above) Vite comes with its own approach of reading and passing environment variables and build modes which is quite easy and handy Static Asset Handling by Vite is something you should probably know before Split your Store on paper When currently using Vuex, you may be lucky, and you have already some modules splitting your store into logical parts. In our case we had just one big store without any modules as the codebase has evolved over time, and we haven&#8217;t made the step to split the store. The migration to Pinia can be a good chance to face this now as Pinia lets you easily compose multiple small stores. You should check your current store configuration and write down the modules that are loosely coupled or even completely independent (e.g. a user or an auth store). Make the migration transparent and estimable The last thing we have done was to create a new epic for the whole migration and to create small estimable tasks. This was very important as we were now able to identify things we can prepare and do even before we started the migration itself and also tasks we can do in advance. On the other hand it helped us for the communication with the product owner and to make things transparent. Please keep in mind to add some time buffer for unexpected things occurring during the migration where you may need some extra time. For example: the migration from Vuex to Pinia took a lot more time than we thought before. But: it was definitely worth it. The TypeScript support is way better and the unification of actions and mutations reduces the Boilerplate code a lot. We also underestimated the time we needed to migrate the tests. This was hard by definition but quite time-consuming as I wrote in the introduction: We had a huge Vuex store. Migrations before the migration Before starting the migration itself you should migrate everything you can, which is not related to Vue 3 / vite. Here is what we have done in my team before the migration itself. Convert Filters to functions Vue 3 kicked out the concept of using filters in the template using the pipe ( | ) syntax ( {{ expression | myFilter }} ). Filters are simply functions that can be imported and used directly. You can already import the functions, use them as a method and then pass through the expression in the template before starting the Vu3 migration: {{ myFilter(expression) }} . Update and migrate dependencies Update all possible dependencies to their latest versions to make migrations for other libs in advance. At this step: double-check if vue-specific libs are ready for using with Vue 3 or if there are other libs you have to use. If you have to change to other libs and this one supports Vue 3, make the migration now. In our team we had already lots of our dependencies updated, since we are using Mend (formerly Whitesource) Renovate for housekeeping and continuous dependency version updates. When you decide to migrate a dependency to a new one that supports Vue 2 and Vue 3 or which should be replaced with a self-implementation: Do it in advance before the actual Vue migration. Isolate hard-to-migrate components It may happens, you realize, for some of your dependencies a migration won&#8217;t be straight-forward. In our case we decided some years ago, we want to use Leaflet.js as our map library to display and interact with features on a map. Therefore we also used a wrapper for Vue 2 applications called Vue2Leaflet which made us use Leaflet in a declarative manner. However, this architectural decision was now a problem for us, as not only this dependency is not supposed to use it with Vue 3 but also extensions for this library such as Leaflet.heat needed to be migrated. To face this issue we&#8217;ve gone one step back and rethink our architectural decision to use Leaflet. At this time there was already a Vue 3 wrapper for leaflet available but not as feature-rich as we needed it. So we created a new Architectural Decision Record (ADR) to evaluate and choose our future map library as it is a central component of our app and can&#8217;t be easily replaced. After doing a Proof-of-Concept (PoC), we decided to switch to OpenLayers and make use of the vue3-openlayers wrapper too, where we were also able to contribute missing features back into the project. This whole story is probably quite special to my team and our app, but the essential thing here was, that we prepared the central components in parallel to our productive app in a separate repository in isolation. Therefore, we created the components and defined their props and events with the help of Storybook . Of course, we also created tests for these components, so that we were prepared to copy over all this into the productive app and replace the existing components later, when we were ready to actually migrate to Vue 3. A drawback with this approach is of course: It probably blocks you with releasing new features or you have to implement them twice during the preparation time (one time for the productive app based on Vue 2, one time for the isolated components based on Vue 3). Update your NPM Scripts When checking your Vue 3 default setup you will notice that some NPM script names have changed by default. For example the default command to run the development build and server is now npm run dev instead of npm run serve . You can either change the names back since you are used to the \"old\" commands, or you can already name your commands in the Vue 2 setup to the new ones to get comfy with it. Please note that you may have to change the commands in you CI/CD Pipeline too. Switch to Vite You can switch to Vite before updating to Vue 3 this makes the \"big bang\" migration a bit smaller. For that, you should install Vite and use the official plugin @vitejs/plugin-vue2 . You also need to migrate all the webpack plugins and configs. When the setup is finished, cleanup all the webpack stuff including the config and the dependencies. During the migration we noticed, that we haven&#8217;t used Type-Only Imports in all our typescript and .vue files. The default Vite setup is configured in such way, Type-Only Imports will be forced when needed, otherwise you&#8217;ll receive errors during the build. We had the option to either deactivate this strict behavior by setting the typescript config option importsNotUsedAsValues to either preserve or remove (not recommended) or to migrate. Luckily, there is a community project called ts-import-types-cli that will automate a part of this step. So we just had to run the following command to migrate to Type-Only Imports at places needed: # remove the `--dry-run` flag to migrate actually and not only list the changes npx ts-import-types-cli --no-organise-imports -p tsconfig.json --dry-run The bad news: The tool didn&#8217;t find all occurrences of the Type-Only Imports, so when running npm run build , we caught some more we had to fix manually. Switch to Vitest After your migration to Vite, you should make use of Vitest as your new pretty and fast unit testing framework. In comparison to Jest it comes with a stable out-of-the-box ESM support and faster test executions. Until now Jest&#8217;s support for ESM is still experimental (State: Jest Version 29.5). The API is quite similar and mostly compatible to jest . If you used Mocha before, the migration shouldn&#8217;t be hard either. Switch to Pinia The next big step you should do in advance is the migration of your Vuex store. You can also do this step after the migration itself and keep Vuex for now. However, we decided, it&#8217;s a good idea, to migrate the store before and switch to Pinia since the API is a lot simpler and better composable when slicing our big store into chunks. Furthermore, it comes with better TypeScript support. At the Pinia-Docs you will find a very detailed Guide for the Migration from Vuex Migrate Components Last but not least we decided to migrate all our components to the composition API with the &lt;script setup&gt; syntactical sugar . This is a step you can also omit or do in advance, but we recommend using this API since it&#8217;s also a bit more performant, and it reduces the boilerplate code you have to write. Finally: Migrate to Vue 3 You are now prepared to migrate to Vue 3, and you&#8217;ve done already a lot of things which made this step much easier and shorter. Now you can start the migration of Vue itself. Keep in mind, that for the actual migration you must migrate the unit tests too as the test utils for vue3 are slightly different. Migrate the source code Here we started by adding Vue 3 as well as the @vue/compat package as described in the Vue 3 Migration Build documentation . Also, we needed to update the VueRouter to version 4.x.x and adjust the configuration. As good step-by-step guides, I would recommend you again to read the following Blogposts: \"Vue.js: How to Migrate a large project from Vue 2 to Vue 3\" from Baptiste Jamin The official Vue 2 to Vue 3 Migration Guide . If you have already prepared some components in isolation to work with Vue 3 as we did: Of course you should replace the old ones and probably adjust the props or events if the API of your new components changed compared to the Vue 2 ones. After this step your whole app should work as before (fingers crossed). The migration of the components itself can be done one by one after the migration until everything is converted to Vue 3. Migrate to @vue/test-utils@v2 After you migrated everything, you need to update to @vue/test-utils@v2 . The migration should be straight-forward when following the migration guide . Nonetheless it can take quite a bit of time depending on the amount of unit tests you have. Post-Migration-Steps Remove Compatibility Package Once every component is migrated, make sure to remove the @vue/compat and it&#8217;s configuration as you don&#8217;t need it anymore. Make use of the Teleport feature Now that we are using Vue 3, we can use the \"Teleport\" feature. Think about components creating their DOM elements deeply in the DOM caused by the component hierarchy but where you would expect the elements to appear somewhere else close to the root. A good example is displaying a modal conditionally: &lt;body&gt; &lt;ComponentOne&gt; &lt;ComponentTwo&gt; &lt;ComponentThree&gt; &lt;MyModal v-if=\"myCondition\"&gt; &lt;/ComponentThree&gt; &lt;/ComponentTwo&gt; &lt;/ComponentOne&gt; &lt;/body&gt; In Vue 2, the modal would be rendered and appear inside the ComponentThree . Using teleport in MyModal can lift the element up to the body tag which makes more sense for common modal dialogs. Conclusion Migrating from Vue 2 to Vue 3 can be a huge thing and takes quite a bit of time. But good preparation and pre-migration will make the whole migration process much easier, more estimable and won&#8217;t block you for so long with releasing new features. Compared to writing the whole thing from scratch, we think this was well worth it. I hope this post gave you some inspiration of how you can face the migration of your project. Happy Migration ‚úåüèº "
},

{
    "id": 5,
    "uri": "blog/2023/2023-05-15-developer-experience-platform-fuer-entwicklerinnen.html",
    "menu": "Blog",
    "title": "Developer Experience Platform",
    "text": " Table of Contents Developer Experience Platform (DXP) f√ºr Entwickler:innen Video Developer Experience Platform (DXP) f√ºr Entwickler:innen Die Developer Experience Platform (DXP) bietet Services f√ºr jede Phase der Software-Entwicklung. Konzern- und Betreibervorgaben sowie Cloud-Richtlinien sind in diesen Services bereits inkludiert. DXP erm√∂glicht damit DB-konzernweit, dass Entwickler:innen schnell, einfach und sicher Deployments vornehmen k√∂nnen und Software-Anwendungen von der Konzeption bis zum produktiven Einsatz schneller entwickelt werden. Das Erkl√§rvideo zeigt dies, indem es Zuschauende in den Alltag von Entwickler:innen ‚Äûentf√ºhrt‚Äú. Video "
},

{
    "id": 6,
    "uri": "blog/2023/2023-05-05-loom-threading.html",
    "menu": "Blog",
    "title": "Projekt Loom ist da",
    "text": " Table of Contents Threading wie es sein soll: Projekt Loom ist da Virtualisierung hilft schon immer ‚Ä¶ und der Weg ins Schlamassel Threads sind die Grundlage der Nebenl√§ufigkeit Asynchrone Programmierung als Notl√∂sung Projekt Loom als Rettung VirtualThreads: benutzen ist (fast) einfacher als vermeiden Anpassungen im eigenen Code Angewohnheiten hinterfragen Synchron war nie schlecht Ausblick: Structured Concurrency Threading wie es sein soll: Projekt Loom ist da Es ist endlich so weit - das lang ersehnte Projekt Loom hat seinen Weg in das JDK gefunden! Seit √ºber f√ºnf Jahren haben wir uns danach gesehnt, all die Kr√ºcken wie NIO , asynchrone Programmierung , CompletableFutures und AsyncServlets hinter uns zu lassen und Java wieder so zu schreiben, wie wir es schon immer wollten. Virtualisierung hilft schon immer Auf jedem Rechner gibt es Ressourcen, die begrenzt sind. CPU-Zeit ist seit jeher eine knappe Ressource. Gleichzeitig m√ºssen jedoch h√§ufig viele kleine Aufgaben erledigt werden. Heutzutage verwenden wir meist API-Backends, die Anfragen √ºber HTTP erhalten. Sie lesen Daten, transformieren sie und ver√§ndern sie gegebenenfalls. Anschlie√üend wird die Antwort per Netzwerk-IO gesendet. Dabei die Ressourcen effizient zu nutzen, war von Anfang an eine Herausforderung und erforderte viel manuelle Arbeit. Zum Gl√ºck hatte Edsger W. Dijkstra bereits im Jahr 1965 die brillante Idee, den Zugriff auf wertvolle Ressourcen zu virtualisieren. So bekam das Berkeley Timesharing System die ersten Threads der Computer-Geschichte. Das Konzept war einfach: Threads sind kosteng√ºnstig und virtualisieren den Zugriff auf wertvolle Ressourcen. Figure 1. Threading wie die Urahnen - mit einer CPU Ein Scheduler sorgt daf√ºr, dass blockierte Threads unterbrochen werden und andere Aufgaben ausgef√ºhrt werden k√∂nnen, bis die notwendigen Ressourcen verf√ºgbar sind. Ein wahrhaft revolution√§res Konzept! Die Welt hat sich seit den ersten Threads des Berkeley Timesharing Systems weiterentwickelt. ‚ÄûModerne‚Äú Betriebssysteme wie AmigaOS haben das Konzept des Threading verbessert, indem sie es dem Betriebssystem erlauben, rechnende Prozesse zu unterbrechen und an anderer Stelle fortfahren zu lassen. Anders als bei User Threads in SunOS , wo der Code im Thread selbst anzeigt, wann er unterbrochen werden soll. ‚Ä¶ und der Weg ins Schlamassel Wir haben seitdem viel getan, um das Thread-Konzept kaputt zu bekommen. Wir nutzen gerade Netz-IO in modernen Anwendungen ganz intensiv. IO ist oft das, was diese Anwendungen am meisten machen. Und auf der anderen Seite ist die Hardware viel schneller als `65 . Wir haben so viele Requests zu verarbeiten und die Rechner sind schnell genug. Das geht. Wir k√∂nnen mal eben eine Million Sockets offenhalten und damit arbeiten. Nur: das Threading selbst kommt nur mit ein paar zehntausend Threads klar. Und deswegen sind inzwischen die Threads selbst die wertvolle Ressource. Und deswegen mussten wir anfangen, die Threads selbst zu teilen, zu poolen und sie wiederzuverwenden. Hierhin f√§llt der Aufstieg der Event-basierten IO-Bibliotheken . Netty f√§llt in diese Kategorie. Figure 2. IO-Thread und Worker-Thread bei der Arbeit IO und Worker Threads: ein speziell f√ºr IO-Operationen abgestellter Thread nimmt Daten entgegen. Dieser Thread wickelt s√§mtliche IO-Operationen ab. Damit entf√§llt auch die Notwendigkeit f√ºr Locking und Synchronisierung. Sobald Daten eingetroffen sind, werden sie in separaten Worker-Threads verarbeitet. Worker-Threads sollen selbst nie blockieren. Es wird dabei meistens nur ein Thread (manchmal einer pro CPU) mit IO beauftragt. Er arbeitet mit ‚Äûnon-blocking IO‚Äú , erh√§lt also Events, sobald eine IO-Operation abgeschlossen ist. Dadurch kann ein Thread alle offenen Sockets auf einmal bearbeiten. Sobald das IO abgeschlossen ist, wandert die Arbeit zu einem Worker-Thread weiter, der Berechnungen vornimmt. So l√§sst sich in unserem Beispiel bei drei gleichzeitig aktiven Requests die Thread-Zahl auf zwei reduzieren. Der Preis daf√ºr ist, dass die Worker-Threads selbst Bescheid geben m√ºssen, wenn sie fertig sind. Da ist dann das ‚Äûalte‚Äú kooperative Multitasking wieder. In der Praxis spielt das aber weniger eine Rolle, weil wir mehrere Worker-Threads benutzen, als Thread-Pool. Trotzdem ‚Äì wir bezahlen gleich mehrere Preise daf√ºr: F√ºr jeden Request gibt es mindestens zwei Thread-Wechsel. Und die sind teuer. Sind Teile der Anwendung rechenintensiv, dann m√ºssen wir selbst daf√ºr sorgen, dass sie niemanden blockieren. Dann gibt es mehrere Thread-Pools. &#8230;&#8203; und wir brauchen ein kluges Threading-Konzept. Meistens hei√üt das, verschiedene Pools f√ºr Rechenlast, Netzwerk und File-IO einzuf√ºhren. Die IO-APIs sind alles andere als einfach zu bedienen. Und immer etwas anders. Netty f√ºr Netzwerk-IO. NIO f√ºr File-IO. RDBC f√ºr den Datenbankzugriff. Threads sind die Grundlage der Nebenl√§ufigkeit Die Kernkonzepte von Java basieren auf Threads. Das gilt f√ºr den Sprachkern, die VM, f√ºrs Debugging und das Profiling. IO-APIs waren synchron und sind in synchroner Form heute noch am √ºbersichtlichsten zu benutzen. Das gesamte Exception-System ergibt nur innerhalb eines Threads wirklich Sinn. Speicherzugriffe innerhalb eines Threads sind geordnet und √ºberschaubar. Wir k√∂nnten am √ºbersichtlichsten alle Arbeit f√ºr einen Request in einem eigenen Thread erledigen. Wir k√∂nnten einfach einen Thread pro Request starten , synchrone APIs verwenden. Aber es geht nicht, weil einfach zu wenige Threads verf√ºgbar sind. Asynchrone Programmierung als Notl√∂sung Als Konsequenz opfern wir den Java-Sprachkern und verwenden reaktive Bibliotheken. Und m√ºssen uns f√ºr Konstrukte wie Schleifen, If und Try-Catch komplett neue Konstrukte einfallen lassen. CompletableFuture .supplyAsync(info::getUrl, pool) .thenCompose(url -&gt; getBodyAsync( pool, HttpResponse.BodySubscribers.ofString(UTF_8))) .thenApply(info::findImage) .thenCompose(url -&gt; getBodyAsync( pool, HttpResponse.BodySubscribers.ofByteArray())) .thenApply(info::setImageData) .thenAccept(this::process) .exceptionally(t -&gt; { t.printStackTrace(); return null; }); Ohne auf den konkreten Inhalt dieses Handlers einzugehen, l√§sst sich die Auswirkung auf die Struktur der Programmiersprache erkennen: Das Programm wird nicht mehr in der √ºblichen Weise strukturiert, sondern √ºber eine \"Fluent API\" erstellt und gestartet. Im Kern stellt das eine Monade dar, wie sie zum Beispiel aus Haskell bekannt ist. Dieses neue Sprachkonstrukt hat eine Reihe von Folgen, die interessant zu nutzen sind. Mit all den Problemen, die daraus resultieren, dass jetzt JVM, Werkzeuge, Sprache und Tools nicht mehr so recht zusammenpassen wollen: In Stack Traces steht oft kaum noch Hilfreiches . Mit dem Debugger durch ein reaktives Programm zu steppen ist eine Herausforderung. Und die Ursache f√ºr Lastprobleme zu finden, ist problematisch. Diesen Programmierstil verwenden wir definitiv nicht, weil er einfacher zu verstehen w√§re. Oder weil er sonst irgendwie n√ºtzlicher zu handhaben w√§re. Wir verwenden diesen Programmierstil, weil wir nicht anders skalieren k√∂nnen. Projekt Loom als Rettung Die Idee hinter Projekt Loom: Threads m√ºssen wieder so billig werden wie damals. Es darf kein Problem sein, Millionen davon zu starten. Die JVM mappt dazu ihre eigene Art von Threads, die dort VirtualThreads hei√üen, auf Betriebssystem-Threads. Das ist ein M:N-Mapping. Also anders als damals zu Solaris-Zeiten, als ‚ÄûGreen Threads‚Äú eben nur auf einen einzigen OS-Thread abgebildet werden konnten. Aber ziemlich so, wie es in Erlang schon immer war. Und auch die Go-Fans lachten ja bereits √ºber uns Java-Menschen. Die JVM kann das deswegen besser als das Betriebssystem, weil es zum einen mehr Wissen besitzt (zum Beispiel √ºber Stack-Gr√∂√üen und das Speichermodell) und zum anderen, weil es Threads nicht jederzeit unterbrechen kann. Stattdessen wird nur dort unterbrochen, wo es blockierende Operationen gibt. Das sind haupts√§chlich IO-Operationen, aber auch dort, wo wir in unseren Programmen manuell synchronisieren. Damit das funktioniert, gab es im Rahmen des Projekts Loom Anpassungen quer durch die JVM und die Basis-Bibliotheken. NIO wurde umgebaut. Das ‚Äûalte‚Äú IO wurde angepasst (und darf und soll damit ruhig wieder benutzt werden). Nur File-IO unter Windows ist noch ein Problem und dauert noch. VirtualThreads: benutzen ist (fast) einfacher als vermeiden Seit Java 19 k√∂nnen wir Threads sehr einfach als ‚Äûvirtual‚Äú starten: var thread = Thread.startVirtualThread(() -&gt; { ... }); Das ist schon alles. Die JVM k√ºmmert sich darum, dass diese VirtualThreads automatisch auf OS-Threads abgebildet werden. Normalerweise auf einen pro CPU-Kern. In diesem VirtualThread lassen sich nach Herzens Lust blockierende Aufrufe, Locks und Sleeps in synchroner Art platzieren. Wir sollen uns keine Gedanken mehr dar√ºber machen, wie der Wettstreit um die Ressourcen l√§uft. Anpassungen im eigenen Code Einige Code-Konstrukte spielen nicht so gut mit VirtualThreads zusammen. Wir k√∂nnen sie ersetzen, damit der Code noch besser skaliert. Ganz weit vorne ist (jedenfalls derzeit) noch der ‚Äûsynchronized‚Äú-Block. Der h√§ngt immer an einem OS-Thread, weil er mit Betriebssystemmitteln implementiert ist. Wir wollen ihn mit ‚ÄûReentrantLock‚Äú oder noch besser mit ‚ÄûStampedLock‚Äú ersetzen. Der zweite Bereich sind JNI-Aufrufe. Die sind immer dann problematisch, wenn sie innerhalb von ‚Äûsynchronized‚Äú passieren. Vor allem, wenn wir von nativem Code wieder nach Java callen, zum Beispiel bei Callbacks. Alles das muss uns aber nicht aufhalten. In den meisten F√§llen machen ein paar wenige solche Stellen wenig aus. Viele Frameworks integrieren VirtualThreads bereits In Spring Boot Projekten werden wir bereits dahin gef√ºhrt, dass wir Threading an zentraler Stelle implementieren. So wie Spring Boot es intern auch bereits macht. Wir k√∂nnen heute schon daf√ºr sorgen, dass Spring Boot auf VirtualThreads setzt: @Configuration class ConfigureVirtualThreads { @Bean(TaskExecutionAutoConfiguration.APPLICATION_TASK_EXECUTOR_BEAN_NAME) public AsyncTaskExecutor asyncTaskExecutor() { return new TaskExecutorAdapter( Executors.newVirtualThreadPerTaskExecutor()); } @Bean public TomcatProtocolHandlerCustomizer&lt;?&gt; protocolHandlerVirtualThreadExecutorCustomizer() { return protocolHandler -&gt; { protocolHandler.setExecutor( Executors.newVirtualThreadPerTaskExecutor()); }; } } Mit der ersten Deklaration wird Spring konfiguriert. Der neue Task-Executor, den Spring an verschiedenen Stellen f√ºr asynchrone Aufrufe nutzt, erh√§lt daf√ºr jeweils einen neuen VirtualThread, statt wie vorher einen Thread-Pool. Die zweite Deklaration konfiguriert den eingebetteten Tomcat, mit dem Spring Boot die Web-Anfragen bearbeitet. Hier ist normalerweise ebenfalls ein Threadpool hinterlegt. Mit der Konfiguration f√§llt dieser Pool weg und es wird jedes Mal ein neuer VirtualThread zur Bearbeitung angelegt. Das als Configuration eingef√ºgt und schon kommen Servlet-Requests bereits fertig als VirtualThread an. Spring Boot hat VirtualThreads auf dem Schirm, passt immer mal wieder etwas an und ist schon recht weit damit, VirtualThreads sehr effizient zu nutzen. Micronaut hat ebenfalls schon Support vorbereitet , der getestet werden kann. Und f√ºr Quarkus gibt es schon sehr weitreichenden Support . Und sogar in Wildfly 27 l√§sst sich VirtualThread-Support aktivieren. Angewohnheiten hinterfragen Mit Projekt Loom m√ºssen wir fast nie neue Konzepte lernen. Stattdessen k√∂nnen wir alte Gewohnheiten ablegen: ThreadPools werden in den meisten F√§llen keinen Mehrwert mehr bieten. Im Gegenteil f√ºgen sie Overhead hinzu und verlangsamen den eigenen Code . Wo wir bisher Poolen, zum Beispiel um die Anzahl gleichzeitig durchgef√ºhrter Requests zu limitieren, k√∂nnen wir wieder (wie fr√ºher) Semaphoren beim Funktionsaufruf nutzen. Synchron war nie schlecht Und dann nat√ºrlich die Erkenntnis: f√ºr 99&#160;% aller Applikationen da drau√üen war asynchrone Programmierung nie n√∂tig. Auch nicht ohne Projekt Loom. Die wenigsten haben mehr als 30.000 gleichzeitige Requests pro Service-Instanz. Moderne Hardware hat damit kein Problem, auch nicht mit 30k Betriebssystem-Threads. Und weil die Stack-Gr√∂√üe nur virtuellen Speicher angibt, haben wir auf 64-Bit-Systemen kein Problem damit. Ausblick: Structured Concurrency Bis mit Java 21 im Herbst 2023 das n√§chste LTS-Release aufschl√§gt, soll auch Structured Concurrency mit aufgenommen sein. Damit lassen sich dann die Stellen √ºbersichtlich angehen, bei denen innerhalb einer Aufgabe Anfragen und Berechnungen parallel erfolgen sollen. @GetMapping(\"/trains\") fun listTrainsParallel(): TrainList&lt;TrainRepresentation&gt; { val list = StructuredTaskScope.ShutdownOnSuccess&lt;List&lt;Train&gt;&gt;().use { scope -&gt; scope.fork { serverA.listActiveSync() } scope.fork { serverB.listActiveSync() } scope.join().result().map { it.toListRepresentation() } } val count = StructuredTaskScope.ShutdownOnSuccess&lt;Int&gt;().use { scope -&gt; scope.fork { serverA.countActiveSync() } scope.fork { serverB.countActiveSync() } scope.joinUntil(Instant.now().plusSeconds(15)).result() } return TrainList(list, count) } Bei den beiden Abfragen k√∂nnen wir einfach (√ºbrigens wieder als Monade) deklarieren, dass die dahinter liegenden Abfragen in separaten Threads erfolgen - im besten Fall in VirtualThreads. \"ShutdownOnSuccess\" sorgt daf√ºr, dass das erste verf√ºgbare Ergebnis gewinnt und alle anderen Threads beendet werden. Wir k√∂nnen einen Timeout mitgeben, um die Laufzeit - hier auf 15 Sekunden - zu begrenzen. Dabei ist wichtig: Es geht bei Structured Concurrency wirklich fast nur um die Lesbarkeit und Wartbarkeit. Schneller oder Ressourcen-sparender wird es dadurch nicht. Also: Es wird spannend im Java-√ñkosystem. Mit Projekt Loom werden tats√§chlich die Karten neu gemischt. Endlich k√∂nnen wir den Programmierstil wieder so aussuchen, wie er zu unseren Gehirnen passt. "
},

{
    "id": 7,
    "uri": "blog/2023/2023-04-09-vortrag-auf-der-javaland.html",
    "menu": "Blog",
    "title": "JavaLand 2023",
    "text": " Table of Contents Vortrag auf der JavaLand 2023 Slides Vortrag auf der JavaLand 2023 Vom 20. bis 23. M√§rz fand mit der JavaLand die gro√üe Java-Community-Konferenz im Phantasialand Br√ºhl statt - und DB Systel war mit dabei. In dem Talk \"Fantastische Diagramme und wie Du sie selbst erstellst\" haben Falk Sippach (embarc) und Ralf D. M√ºller (DB Systel) gemeinsam Schwachstellen von Architekturdiagrammen aufgesp√ºrt und ausgemerzt. In den Slides des Vortrags (siehe Download-Link unten) finden sich als Ergebnis ein paar Tipps und Checklisten, die jeder f√ºr seine eigenen Diagramme verwenden kann. Abends gab es dann noch einen Fun-Workshop \"Hacking the RP2040\", bei dem wir uns angesehen haben, was man so alles mit dem Tufty-Badge von Pimoroni anstellen kann. Dabei handelt es sich um ein kleines 320x240 Display mit Tastern und RP2040 Microcontroller (besser bekannt als Raspberry Pi Pico) in der Form eines Badges zum Umh√§ngen. Das eigentliche Highlight der j√§hrlichen JavaLand war aber die Community mit ihren vielen Hallway-Tracks und dem Newcomer-Programm \"NextGen\" √ºber das immer wieder frische Themen und Sichtweisen in das Programm aufgenommen werden. Slides Slides des Workshops "
},

{
    "id": 8,
    "uri": "blog/2023/2023-04-01-Indoor-GIS-zur-Rationalisierung-von-Wartungsarbeiten.html",
    "menu": "Blog",
    "title": "Indoor-GIS",
    "text": " Table of Contents Indoor-GIS zur Rationalisierung von Wartungsarbeiten Slides Indoor-GIS zur Rationalisierung von Wartungsarbeiten Genial kombiniert: Mit Tracking-Technologie und unserer Esri-Plattform Kosten und Durchlaufzeiten reduzieren. Durch die Kombination von Tracking-Technologie und unserer Esri-Plattform nutzen wir die modernsten Tracking-Systeme. Auf diese Weise reduzieren wir Kosten und Durchlaufzeiten. Eine Erfolgsgeschichte in der Arbeitswelt. Erfahren Sie, wie die offene Plattformarchitektur viele Anwendungsf√§lle erm√∂glicht. Beispiele finden Sie in der beigef√ºgten Pr√§sentation. Sie wurde im Rahmen eines Vortrags von Konrad Winkler &amp; Philippe Rieffel im Rahmen der Esri International Infrastructure Management &amp; GIS Conference am 18.04.2023 in Frankfurt gezeigt. Hinweis: Die Pr√§sentation liegt in englischer Sprache vor. Slides download "
},

{
    "id": 9,
    "uri": "blog/2023/2023-03-28-ChatGPT-Einblicke-und-mehr-Generative-Sprachmodelle-Herausforderungen-und-Chancen.html",
    "menu": "Blog",
    "title": "ChatGPT",
    "text": " Table of Contents ChatGPT ‚Äì Funktionsweise, Chancen, Risiken und Alternativen einfach erkl√§rt Video ChatGPT ‚Äì Funktionsweise, Chancen, Risiken und Alternativen einfach erkl√§rt In diesem Video erkl√§re ich leichtverst√§ndlich die Funktionsweise von ChatGPT im Zusammenhang mit generativer K√ºnstlicher Intelligenz (Generative AI) und gro√üen Sprachmodellen (Large Language Models, kurz LLMs). Anhand von Anwendungsf√§llen beschreibe ich Chancen, Risiken und Alternativen und diskutiere, was das f√ºr uns und unsere Jobs zuk√ºnftig bedeuten k√∂nnte.¬† Video "
},

{
    "id": 10,
    "uri": "blog/2023/2023-03-08-Re-Platforming-Mainframe-Mehr-als-nur-Lift-Shift.html",
    "menu": "Blog",
    "title": "Re-Platforming Mainframe",
    "text": " Table of Contents Re-Platforming Mainframe ‚Äì Mehr als nur Lift&amp;Shift Slides Re-Platforming Mainframe ‚Äì Mehr als nur Lift&amp;Shift Die sinkende Bedeutung der Mainframe-Plattform f√ºhrt uns zu unserem Projektziel Lift&amp;Shift. Die Migration in die Cloud soll mit m√∂glichst wenigen Anpassungen erfolgen. Dabei wollen wir die IBM Mainframe basierten Cobol Anwendungen durch schrittweise √úberf√ºhrung der Anwendungen in die DB Enterprise Cloud abl√∂sen. Die Schaffung einer zukunftsorientierten IT-Architektur und signifikante Einsparungen von Betriebskosten durch die Nutzung cloudbasierter Infrastruktur sind ebenso wichtig. Lesen Sie in unserer Pr√§sentation, welche Projektziele wir au√üerdem verfolgen, wer unsere Partner sind und wie unsere Bestandsanalyse aussieht. Gezeigt wurde sie im Rahmen eines Vortrags von Tim Engeleiter am 08.03.2023 bei den Mainframe Dayz in Wiesbaden.¬†¬† Slides download "
},

{
    "id": 11,
    "uri": "blog/2022/2022-11-24-the-journey-towards-K8s-at-Deutsche-Bahn.html",
    "menu": "Blog",
    "title": "K8s at Deutsche Bahn",
    "text": " Table of Contents The journey towards K8s at Deutsche Bahn Video The journey towards K8s at Deutsche Bahn This lecture was given by Gualter Barbas Baptista from DB Systel at the Containerdays from 05 to 07 September 2022. ( https://www.containerdays.io/ ) In 2016, Deutsche Bahn decided to get rid of their own data centers and to migrate the majority of applications to the cloud. The cloudification of Deutsche Bahn was supported by a comprehensive transformation of its digital partner DB Systel from traditional working and organisational structures to self-organisation and company-wide networks, including a DevOps culture. Within this context, the first Kubernetes platform services emerge. From an OpenShift-based Kubernetes-Namespace-as-a-Service into a GitOps based K8s fleet management, we describe how the cloud, the organisational transformation and the CNCF landscape are accelerating the digitalisation of Deutsche Bahn. Video "
},

{
    "id": 12,
    "uri": "blog/2022/2022-11-04-Produkt-statt-Projekmanagement.html",
    "menu": "Blog",
    "title": "Produkt- statt Projektmanagement",
    "text": " Table of Contents Produkt- statt Projektmanagement Video Produkt- statt Projektmanagement Warum das Funding von Projekten mittlerweile zu einem der gr√∂√üten Hindernisse auf dem Weg zu einer BizDevOps-Organisation geworden ist ‚àí ein Debattenbeitrag zum n√§chsten notwendigen Schritt der DevOps-Bewegung. Die DevOps-Bewegung ist in der Realit√§t und im Herzen der digitalen Industrie angekommen. In der Systel arbeiten knapp 100 Teams nach dem Prinzip ‚ÄûYour build (or integrate) it, you run it‚Äú und sind so in der Lage, regelm√§√üig und mit hoher Frequenz √Ñnderungen und damit ‚ÄûBusiness Value‚Äú zu den Nutzerinnen und Nutzern zu bringen. Nicht nur bei uns, sondern in allen vergleichbaren gro√üen Konzernen sind Cloud-Nutzung, Automatisierung, Continuous Delivery, Platform Strategy und der daf√ºr notwendige kulturelle Wandel auf der Tagesordnung. Ein gro√üer Hebel f√ºr den Wandel zu einer DevOps-Organisation wird allerdings h√§ufig √ºbersehen: das etablierte Funding von digitalen Ma√ünahmen √ºber Projekte ist mittlerweile zu einem der Haupt-Hindernisse auf dem Weg zu einer leistungsf√§higen Delivery-Organisation geworden. Aus meiner Sicht m√ºssen wir daher ganz vorne mit der Ver√§nderung ansetzen, n√§mlich dort, wo Projekte entstehen, und √ºber Projektbudgets entschieden wird. Warum ich dieser Meinung bin, habe ich auf einem Vortrag beim DevOps Enterprise Summit dargelegt, der mittlerweile auch √ºber den YouTube Kanal der DB Systel zug√§nglich ist. Video "
},

{
    "id": 13,
    "uri": "blog/2022/2022-10-21-Deine-Diagramme-sind-Legende.html",
    "menu": "Blog",
    "title": "Deine Diagramme sind Legende?",
    "text": " Table of Contents Deine PlantUML-Diagramme sind Legende? pre { white-space: pre-wrap; } table.tableblock { overflow: auto; width: 100%;} td.tableblock {overflow: auto; width: 50%;} Deine PlantUML-Diagramme sind Legende? &#8230;&#8203;dann verpasse ihnen eine Legende! Ein Diagramm soll nicht nur f√ºr Insider lesbar sein. Mit einer Legende erkl√§rst du die verwendeten Symbole und Farben. In diesem Artikel zeige ich dir, wie es geht. PlantUML verf√ºgt √ºber ein wenig dokumentiertes Element namens \" Legend \". Damit l√§sst sich eine Box im Diagramm z. B. in der rechten unteren Ecke platzieren. Wie aber der Inhalt dargestellt werden soll ist unklar. @startuml skinparam actorStyle awesome database Datenbank :User: -&gt; [Komponente] [Komponente] -&gt; Datenbank #green legend right &lt;b&gt;Legende&lt;/b&gt; ??? endlegend @enduml Google findet als Idee, dass die Legende als Tabelle in Creole-Syntax erstellt werden kann. Farben kann man damit gut erkl√§ren, aber f√ºr Symbole k√∂nnen nur Emojis oder spezielle Zeichen verwendet werden. @startuml skinparam actorStyle awesome database Datenbank :User: -&gt; [Komponente] [Komponente] -&gt; Datenbank #green legend right &lt;b&gt;Legende&lt;/b&gt; | &lt;#red&gt; | Benutzer-Zugriff | | &lt;#green&gt; | Datenbank-Verbindung | | &lt;:smiley:&gt; | Benutzer :-) | endlegend @enduml In einem Forum habe ich am Rande den Hinweis gefunden, dass man mit dem Map-Statement des Objektdiagramms auch eine Tabelle aufbauen kann. Nur geht das nicht direkt innerhalb der Legende. Es gibt aber den Trick, dass man mit der `{{ &#8230;&#8203; }} Syntax ein neues Diagramm innerhalb des Diagramms erstellen kann. Damit l√§sst sich dann auch eine Map innerhalb der Legende aufbauen. @startuml skinparam actorStyle awesome database Datenbank :User: -&gt; [Komponente] [Komponente] -&gt; Datenbank #green legend right {{ map \"&lt;b&gt;Legende&lt;/b&gt;\" as legend #white { &lt;#red&gt; =&gt; Benutzer-Zugriff &lt;#green&gt; =&gt; Datenbank-Verbindung &lt;:smiley:&gt; =&gt; Benutzer :-) } }} endlegend @enduml Und wenn wir jetzt schon dabei sind Diagramme innerhalb von Diagrammen zu nutzen, dann k√∂nnen wir das auch noch eine Ebene tiefer machen. Dadurch schaffen wir es in der Legende die Diagramm-Elemente zu zeichnen, die wir beschreiben wollen. Dazu bauen wir uns in einer Prozedur ein universelles Mini-Diagramm: scale $scale skinparam backgroundcolor transparent label \" \" as A label \" \" as B $type Der scale-Befehl erlaubt es die zu beschreibende Komponente kleiner darzustellen und somit die Legende kompakt zu halten. Die beiden unsichtbaren Labels sorgen daf√ºr, dass wir einen Connector von A nach B darstellen k√∂nnen. Das ganze sieht dann kompakt wie folgt aus: @startuml skinparam actorStyle awesome database Datenbank :User: -&gt; [Komponente] [Komponente] -&gt; Datenbank #green legend right {{ !procedure $entry($type, $label, $scale=1) {{\\nscale $scale \\nskinparam backgroundcolor transparent\\nlabel \" \" as A\\nlabel \" \" as B\\n $type \\n}} =&gt; $label !endprocedure map \"&lt;b&gt;Legende&lt;/b&gt;\" as legend #white { $entry(\":Actor:\",\" Benutzer\", 0.5) $entry(\"[component]\",\" Benutzer\", 0.7) $entry(\"database db\",\"Datenbank\", 0.7) $entry(\"A -&gt; B\",\"Benutzer-Zugriff\") $entry(\"A -&gt; B #green\",\"Datenbank-Verbindung\") } }} endlegend @enduml Im letzten Schritt m√∂chte ich die Legende mit ein paar Styles noch aufh√ºbschen. Der doppelte Rahmen soll weg und etwas kleiner w√§re auch nicht schlecht. @startuml skinparam actorStyle awesome skinparam legendBackgroundColor transparent skinparam legendBorderColor transparent database Datenbank :User: -&gt; [Komponente] [Komponente] -&gt; Datenbank #green legend right {{ scale 0.8 skinparam defaultFontSize 14 skinparam BackGroundColor transparent skinparam defaultBackgroundColor white !procedure $entry($type, $label, $scale=1) {{\\nscale $scale \\nskinparam backgroundcolor transparent\\nlabel \" \" as A\\nlabel \" \" as B\\n $type \\n}} =&gt; $label !endprocedure map \"&lt;b&gt;Legende&lt;/b&gt;\" as legend #white { $entry(\":Actor: #green\",\"\\nBenutzer\", 0.5) $entry(\"[component]\",\"\\nBenutzer\", 0.7) $entry(\"database db\",\"\\nDatenbank\", 0.7) $entry(\"A -&gt; B\",\"Benutzer-Zugriff\") $entry(\"A -&gt; B\",\"Datenbank-Verbindung\") } }} endlegend @enduml Bei der Nutzung f√§llt schnell auf, dass die Legende zu viel Platz einnimmt. Sie duldet keine anderen Diagramm-Elemente neben sich. Also haben wir weiter geforscht. Mit dem Diagramm in der Legende besteht eigentlich kein Grund mehr wirklich das Element Legend zu verwenden. Was passiert, wenn wir es durch eine rectangle ersetzen und diese entsprechend Stylen? Dazu m√ºssen wir dem Element einen Stereotype verpassen, da wir sonst alle rectangle -Elemente stylen w√ºrden. Und siehe da, es funktioniert. Durch diesen Trick haben wir nun mehr Einfluss auf die Platzierung, denn wir k√∂nnen dieses rectangle -Element durch versteckte Verbindungen beeinflussen. @startuml skinparam actorStyle awesome database Datenbank :User: -&gt; [Komponente] [Komponente] -down-&gt; Datenbank #green rectangle a &lt;&lt;test&gt;&gt; Datenbank -left-&gt; a skinparam rectangle&lt;&lt;legend&gt;&gt; { backgroundColor transparent borderColor transparent shadowing false } hide &lt;&lt;legend&gt;&gt; stereotype rectangle legende &lt;&lt;legend&gt;&gt; [ {{ scale 0.8 skinparam defaultFontSize 14 skinparam BackGroundColor transparent skinparam defaultBackgroundColor white !procedure $entry($type, $label, $scale=1) {{\\nscale $scale \\nskinparam backgroundcolor transparent\\nlabel \" \" as A\\nlabel \" \" as B\\n $type \\n}} =&gt; $label !endprocedure map \"&lt;b&gt;Legende&lt;/b&gt;\" as legend #white { $entry(\":Actor:\",\"\\nBenutzer\", 0.5) $entry(\"[component]\",\"\\nBenutzer\", 0.7) $entry(\"database db\",\"\\nDatenbank\", 0.7) $entry(\"A -&gt; B\",\"Benutzer-Zugriff\") $entry(\"A -&gt; B #green\",\"Datenbank-Verbindung\") } }} ] User -[hidden]-&gt; legende legende -[hidden]down-&gt; a @enduml √úbrigens: PlantUML m√∂chte Elemente und ihre Verbindungen immer optimiert platzieren. Es kann also sein, dass die neue Legende deshalb noch mal kr√§ftig durchmischt. Es gibt aber nicht nur die Pfeildefinition -[hidden]&#8594; , um eine Verbindung nicht anzuzeigen. Der Pfeil -[norank]&#8594; ist eine Verbindung, welche bei besagter Optimierung ignoriert wird. Beide Features kann man kombinieren: Mit einem -[norank,hidden]&#8594; ist die Legende unsichtbar mit einem anderen Element verbunden, ohne dass dies das Diagramm umstrukturiert. "
},

{
    "id": 14,
    "uri": "blog/2022/2022-03-23-Vielfalt-bei-der-Bahn-Computerlinguistinnen-treiben-Digitalisierung-voran.html",
    "menu": "Blog",
    "title": "Vielfalt bei der Bahn",
    "text": " Table of Contents Vielfalt bei der Bahn: Computerlinguist:innen treiben Digitalisierung voran Video Vielfalt bei der Bahn: Computerlinguist:innen treiben Digitalisierung voran Dieses Mal haben wir Claudia Sch√∂nfelder aus dem Team SALT zu Gast, mit der wir √ºber das Thema ‚ÄúSINUS‚Äù, den Sprachassistenten f√ºr die Instandhaltung von Z√ºgen, und den Beruf der Computerlinguist:innen, sprechen. Claudia entwickelt multidisziplin√§r mit mehreren Teams von Expert:innen einen der ersten Sprachassistenten f√ºr die industrielle Nutzung. Wir alle kennen Siri und Alexa, aber diese bew√§ltigen in der Regel Aufgaben des Alltags. Im Gegensatz dazu f√ºhrt SINUS die Konzernpartner:innen aus der Instandhaltung per Sprache durch digitalisierte Formulare, um die Eingabe von Sch√§den an Loks g√§nzlich √ºber die Spracherkennung zu t√§tigen. Im Interview spricht sie mit uns √ºber dieses ehrgeizige Projekt, das die Effizienz bei der Befundung von Z√ºgen deutlich steigern kann. Wir spielen anhand eines Beispiels durch, welche Besonderheiten dieses Tool bei der Befundung besitzt. Dazu erkl√§rt Claudia wie sich das Berufsbild der Computerlinguisten in den letzten Jahren entwickelt und etabliert hat. Information, die auch f√ºr die j√ºngeren unter uns, von gro√üem Interesse sein kann.¬†¬† Video "
},

{
    "id": 15,
    "uri": "blog/2021/2021-11-02-KITT-das-Kuenstliche-Intelligenz-Translation-Tool.html",
    "menu": "Blog",
    "title": "KITT Tool",
    "text": " Table of Contents KITT, das K√ºnstliche Intelligenz Translation Tool Video KITT, das K√ºnstliche Intelligenz Translation Tool Dieses Mal haben wir Pia Schwarz aus dem Team SALT zu Gast, mit der wir √ºber das Thema ‚ÄúKITT‚Äù, das K√ºnstliche Intelligenz Translation Tool, sprechen. Pia bringt mit ihrem Team Maschinen das Sprechen bei. Im Interview spricht sie mit uns √ºber KITT, das als Interface gesprochene Sprache entgegennimmt. Es wird eingesetzt, um die Kommunikation im Zugfunk von Fahrdienstleiter:innen und Triebfahrzeugf√ºhrer:innen im Grenzbereich von Frankreich und Deutschland zu verbessern. Wir spielen anhand eines Beispiels durch, welche Besonderheiten das Bahnjargon mit sich bringt und warum am Markt verf√ºgbare √úbersetzungstool in diesem Anwendungsfall nicht ausreichend sind. KITT hilft ebenso die Anforderungen an das Sprachniveau zu senken, in dem es sogenannte Predefined Messages zuverl√§ssig √ºbersetzt, die im europ√§ischen Bahnverkehr verwendet werden. In der zweiten H√§lfte des Interviews steigen wir tiefer in die Technik ein und gehen auf die Herausforderungen ein. Denn die Anforderungen an KITT sind nicht weniger, als exakte √úbersetzungen zu produzieren. Zum Beispiel sind √úbersetzungen bei Hintergrundger√§uschen oder S√§tze mit Eigennamen problematisch. Zum Abschluss sprechen wir √ºber die technische Umsetzung, Trainingsdatenmenge und Open Source Frameworks. Video "
},

{
    "id": 16,
    "uri": "blog/2021/2021-06-08-Bad-bots-Chancen-und-Herausforderungen-fuer-KI-und-Sprache.html",
    "menu": "Blog",
    "title": "Bad Bots",
    "text": " Table of Contents Bad Bots - Chancen und Herausforderungen f√ºr KI und Sprache Video Bad Bots - Chancen und Herausforderungen f√ºr KI und Sprache Sascha Wolter, Chief Advisor Conversational AI bei der DB Systel GmbH, hielt diesen Vortrag am 06.05.2021 im Rahmen der Digital Office Conference 2021 von Bitkom. Kaum jemand scheint seine Alexa nach mehr als dem Wetter oder schlechten Witzen zu fragen. Und vier der f√ºnf erfolgreichsten Alexa Skills erzeugen nicht mehr als Pupsger√§usche. Dies steht in einem krassen Widerspruch zu den Berichten √ºber k√ºnstliche Intelligenz in den Medien, denen zufolge weltbeherrschende Computer wie Skynet (Terminator) unmittelbar bevorstehen. Und selbst die, die den technische Fortschritt weniger als Bedrohung denn als Chance verstehen, haben oft eine v√∂llig falsche Vorstellung von den M√∂glichkeiten von #Chatbots und #Sprachassistenten. Nicht selten wird davon ausgegangen, dass ‚Äì sofern man ausreichend Daten hat ‚Äì die #KI alles automatisch erledigt und sich der Erfolg mehr oder weniger von ganz allein einstellt. Dies ist offensichtlich noch nicht so, wie die vielen schlechten Bots im Markt eindrucksvoll zeigen. Doch wie man diesem Ziel zumindest m√∂glichst nahe kommt, zeigt Sascha Wolter anhand zahlreicher praktischer Beispiele. Er behandelt nicht nur die Hintergr√ºnde, sondern zeigt auch technische und gestalterische L√∂sungen.¬† Video "
},

{
    "id": 17,
    "uri": "blog/2021/2021-04-12-Computer-Vision-Use-Cases-at-Deutsche-Bahn.html",
    "menu": "Blog",
    "title": "Computer Vision Use Cases",
    "text": " Table of Contents Computer Vision Use Cases @ Deutsche Bahn Video Computer Vision Use Cases @ Deutsche Bahn Wie k√∂nnen KI-Bildanalysen bei der Graffiti-Erkennung helfen und welche Potentiale birgt das f√ºr die Bahn? Im Rahmen des Data Festivals 2021 pr√§sentierte das DB Systel Venture vsion.ai gemeinsam mit der Data Science Beratung Alexander Thamm Einsatzm√∂glichkeiten von KI-Analysen auf Bildern im Bahnkontext. Am Beispiel der automatischen Erkennung von Graffiti auf Z√ºgen zeigt Peco Elenchevski die Besonderheiten des Use Cases auf sowie die technische Umsetzung eines Proof of Concept. Nico Becker kn√ºpft dort an und beschreibt die Herausforderungen, welche sich aus dem Deployment von KI-Modellen ergeben. Dabei skizziert er einen Weg, wie sich ein Proof of Concept zu einem robusten Produktivsystem weiterentwickeln l√§sst. Der Vortrag wurde vor internationalem Publikum gehalten und ist daher auf Englisch. Video "
},

{
    "id": 18,
    "uri": "blog/2021/2021-03-20-Die-C4-Testpyramide-eine-architekturgetriebene-Teststrategie.html",
    "menu": "Blog",
    "title": "Die C4-Testpyramide",
    "text": " Table of Contents Die C4-Testpyramide - eine architekturgetriebene Teststrategie Video Die C4-Testpyramide - eine architekturgetriebene Teststrategie Die Pr√§sentation zeigt, wie sich die Prinzipien der Test Pyramide mit dem C4 Modell zur Visualisierung von Software Architekturen verbinden lassen, um so auf einfache Weise zu einer produktspezifischen Teststrategie zu gelangen. Video "
},

{
    "id": 19,
    "uri": "blog/2020/2020-12-07-devops-mehr-geschwindigkeit-auf-der-schiene.html",
    "menu": "Blog",
    "title": "DevOps Geschwindigkeit",
    "text": " Table of Contents DevOps - Mehr Geschwindigkeit auf der Schiene Slides und Video DevOps - Mehr Geschwindigkeit auf der Schiene In diesem Vortrag im Rahmen der IT-Tage 2020 erkl√§rt Carsten Hoffmann von der DB Systel, warum sich der erste Ansatz einer zentralen CI/CD-Installation im Projekt, eine Cloud-native Plattform f√ºr API-getriebene Softwareentwicklung aufzubauen, f√ºr alle Teams als problematisch erwies und durch dezentrale Pipelines ersetzt wurde. Danach werden die Hindernisse bei der Einf√ºhrung einer eingekauften API-Management-L√∂sung erkl√§rt und wieso sich der Einkauf von gro√üer On-Premise-Software nur schwierig mit den agilen Prinzipien vereinbaren l√§sst. Au√üerdem wird erl√§utert, wie im Team mit polyglotter Softwareentwicklung und permanent gegen Wissensinseln angek√§mpft wurde. Zuletzt geht Casten Hoffmann darauf ein, wie das Team mit umfassender Architekturdokumentation begonnen hat und gescheitert ist. Slides und Video "
},

{
    "id": 20,
    "uri": "blog/2020/2020-05-19-5vue-js-vs-angular-was-ist-besser.html",
    "menu": "Blog",
    "title": "Vue.js vs. Angular",
    "text": " Table of Contents Vue.js vs. Angular: Was ist besser? Video Vue.js vs. Angular: Was ist besser? Heute zu Gast bei #000000 #c0ffee ‚Äì Der Tech-Talk der DB Systel. Von Techies f√ºr Techies: Danny Koppenhagen Danny ist Frontend-Entwickler mit den Schwerpunkten Angular und Vue.js und einer der Autoren des Buches ‚ÄûAngular - Grundlagen, fortgeschrittene Themen und Best Practices‚Äú. Im dx.house Berlin ber√§t er au√üerdem Kunden und Teams in den Themen User Experience von Enterprise-L√∂sungen. Er engagiert sich in der Web Community der DB Systel und ist Mitglied im Themen Team Web der Architekturgilde. Dort erarbeitet er Architektur-Standards f√ºr alle Themen Web. Im Interview spricht er √ºber seine Erfahrungen mit Vue.js und Angular. Er geht darauf ein, welches Framework sich f√ºr welche Anwendungszwecke eignet. So bietet Vue.js haupts√§chlich Vorteile, wenn es um die Integration in bestehende Anwendungen handelt und das Team gerne JavaScript einsetzt. Angular ist im Enterprise-Umfeld f√ºr neue Anwendungen interessant, da es auf TypeScript aufsetzt, ein umfangreiches √ñkosystem mitbringt und zum Beispiel Migrationsguides und Templating-F√§higkeiten √ºber sogenannte Schematics mitbringt. Au√üerdem erl√§utert Danny wie der aktuelle Stand der Technik f√ºr Progressive Webapps (PWA) ist. Hier kommt es darauf an, ob alle ben√∂tigten Features des Betriebssystems angesprochen werden k√∂nnen. Falls nicht, sollte in Erw√§gung gezogen werden eine native App zu entwickeln. Im dritten Teil sprechen wir √ºber die Anbindung von APIs. Um die Orchestrierung von APIs zu vereinfachen, kann hier das Architekturmuster Backend For Frontends zum Einsatz kommen. Das vereinfacht den Zugriff aus der Anwendung, da die Anbindung der APIs nicht einzeln im Frontend implementiert werden muss. Video "
},

{
    "id": 21,
    "uri": "blog/2020/2020-03-27-DB-Systel-streitet-auf-der-OOP-fuer-guten-Code.html",
    "menu": "Blog",
    "title": "OOP: Guter Code",
    "text": " Table of Contents DB Systel streitet auf der OOP f√ºr guten Code Video DB Systel streitet auf der OOP f√ºr guten Code In diesem unterhaltsamen Pecha Kucha Vortrag spricht Carsten Thurau √ºber seine Erfahrung aus dem Alltag als erfahrener Trainer und Coach. Er zeigt in seinem Kurzvortrag, warum schlechter Code Entwickler ungl√ºcklich macht und Code Reviews, TDD und Clean Code eine gute Idee sind. Fazit: Entwickelt qualitativ hochwertigen Code und seid stolz auf Euer Werk! Der Talk wurde auf der OOP 2020 Konferenz in M√ºnchen Anfang Februar 2020 aufgezeichnet. Video "
},

{
    "id": 22,
    "uri": "blog/2019/2019-09-13-Spock-und-AsciiDoc.html",
    "menu": "Blog",
    "title": "Spock und AsciiDoc",
    "text": " Table of Contents Spock und AsciiDoc - vom Test zur Spezifikation und zur√ºck Slides und Video Spock und AsciiDoc - vom Test zur Spezifikation und zur√ºck Spock ist ein Testframework f√ºr Webanwendungen, mit dem man unter anderem den Behavior Driven Development Ansatz, kurz BDD, verfolgen kann. Der Product Owner beschreibt das Verhalten einer Applikation und der Entwickler √ºberpr√ºft es √ºber einen automatischen Test. Dem Entwickler reicht die Ausgabe \"PASSED\" oder \"FAILED\", denn er kennt ja den Code seiner Tests. W√§re es nicht cool, wenn auch der Product Owner ein verst√§ndliches Dokument bek√§me? Kein Problem! Wir generieren √ºber ein Template einfach einen Test-Report in AsciiDoc und f√ºgen weitere erkl√§rende Texte hinzu um eine les- und ausf√ºhrbare Spezifikation zu erhalten. Screenshots aller wichtigen Schritte bereichern die Spezifikation weiter. Sollte aber die Spezifikation nicht am Anfang stehen? Und warum Spezifikation, wenn wir agil sein wollen? Richtig! Stellen wir also eine iterative Feature-Beschreibung an den Anfang und verfeinern diese mit automatischen Tests um am Ende eine gut lesbare und verifizierbare Spezifikation des Verhaltens unseres Systems zu erhalten! Die Vorteile liegen auf der Hand ‚Äì die Vorgehensweise verbessert die Kommunikation zwischen Product Owner und Entwicklern und am Ende bekommen wir ein Dokument welches Ihre wertvolle Software korrekt und √ºberpr√ºfbar beschreibt. Slides und Video "
},

{
    "id": 23,
    "uri": "blog/index.html",
    "menu": "Blog",
    "title": "√úbersicht",
    "text": " Table of Contents √úbersicht √úbersicht Willkommen auf dem Tech Blog der DB Systel. "
},

{
    "id": 24,
    "uri": "blog/profiles/Ralf-D.-Mueller.html",
    "menu": "Autoren",
    "title": "Ralf D. M√ºller",
    "text": " Table of Contents Ralf D. M√ºller Ralf D. M√ºller span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } Ralf is a Software Engineering Advocate at DB Systel GmbH during the day and after sunset he loves everything with bits and bytes. The last few years of his career, he focused on the documentation of software systems with arc42 and the Docs-as-Code approach. You can follow him on mastodon rdmueller@mastodontech.de . "
},

{
    "id": 25,
    "uri": "blog/profiles/Philippe-Rieffe.html",
    "menu": "Autoren",
    "title": "Philippe Rieffe",
    "text": " Table of Contents Philippe Rieffe Philippe Rieffe span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } "
},

{
    "id": 26,
    "uri": "blog/profiles/Konrad-Winkler.html",
    "menu": "Autoren",
    "title": "Konrad Winkler",
    "text": " Table of Contents Konrad Winkler Konrad Winkler span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } "
},

{
    "id": 27,
    "uri": "blog/profiles/Dr.-Martin-Strunk.html",
    "menu": "Autoren",
    "title": "Dr. Martin Strunk",
    "text": " Table of Contents Dr. Martin Strunk span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } Dr. Martin Strunk Dr. Martin Strunk has been working for more than 22 years in different expert and management roles in development and operations at DB Systel. In 2018 Dr. Martin Strunk initiated and lead the DevOps-Transformation Project ‚ÄúTwo Deployments per Day (2D/d)‚Äù at DB Systel, where the technical, organizational and cultural foundations for a DevOps IT delivery model have been created. Currently, he leads as an Agility Master the Customer Experience Unit of DB Systel with more than half a dozen engineering teams that work according to the ‚ÄúYou build it, you run it‚Äù-paradigm. LinkedIn Xing "
},

{
    "id": 28,
    "uri": "blog/profiles/Danny-Koppenhagen.html",
    "menu": "Autoren",
    "title": "Danny Koppenhagen",
    "text": " Table of Contents Danny Koppenhagen Links Danny Koppenhagen span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } Danny is an experienced frontend architect at DB Systel GmbH which is the digital partner of the biggest German railway company Deutsche Bahn . He develops and architects‚Äô enterprise web applications within a DevOps team facing the micro mobility market. Furthermore, he is an open-source enthusiast and one of the authors of the popular German-language Angular book . Links Mastodon Profile X (formerly known as Twitter) Profile GitHub Profile Personal Website "
},

{
    "id": 29,
    "uri": "blog/profiles/Christian-Fischer.html",
    "menu": "Autoren",
    "title": "Christian Fischer",
    "text": " Table of Contents Christian Fischer Christian Fischer span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } "
},

{
    "id": 30,
    "uri": "blog/profiles/Sascha-Wolter.html",
    "menu": "Autoren",
    "title": "Sascha Wolter",
    "text": " Table of Contents Sascha Wolter Links Sascha Wolter span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } Sascha Wolter ist Experte f√ºr die Planung und Umsetzung von ger√§te√ºbergreifenden Anwendungen. Als solcher begeistert er sich f√ºr das Benutzererlebnis und erkundet verbesserte multimodale Interaktionsformen zwischen Mensch und Maschine ‚Äì u. a. in Form von Konversation √ºber Text (Chatbots) und Sprache (auch als Alexa bekannt). Bereits seit 1995 arbeitet er als Berater, Dozent, Sprecher und Autor. In seiner Freizeit begeistert er sich f√ºr Bergsport von Wandern bis Ski und genie√üt guten italienischen Kaffee. Er ist Chief Advisor f√ºr Conversational AI bei DB Systel, TecCo Lead HMI bei Deutsche Bahn und er engagiert er sich als Vorstandsmitglied im Arbeitskreis Usability &amp; User Experience der BITKOM. F√ºr sein Developer- und Community-Engagement wurde er mehrfach als Google Developer Expert f√ºr den Google Assistant (GDE) ausgezeichnet. Vorher war er Senior UX Consultant und Principal Technology Evangelist bei der Conversational AI Platform Company Cognigy, arbeitete er als Senior Developer Evangelist bei der Deutschen Telekom (u. a. Smart Home), als Senior Technology Evangelist f√ºr Alexa bei Amazon und als Freiberufler. Links LinkedIn Personal Website "
},

{
    "id": 31,
    "uri": "blog/profiles/Marcus-Suemnick.html",
    "menu": "Autoren",
    "title": "Marcus S√ºmnick",
    "text": " Table of Contents Marcus S√ºmnick Marcus S√ºmnick span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } "
},

{
    "id": 32,
    "uri": "blog/profiles/Johannes-Dienst.html",
    "menu": "Autoren",
    "title": "Johannes Dienst",
    "text": " Table of Contents Johannes Dienst Johannes Dienst span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } "
},

{
    "id": 33,
    "uri": "blog/profiles/Carsten-Hoffmann.html",
    "menu": "Autoren",
    "title": "Carsten Hoffmann",
    "text": " Table of Contents Carsten Hoffmann Carsten Hoffmann span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } "
},

{
    "id": 34,
    "uri": "blog/profiles/buildIT.html",
    "menu": "Autoren",
    "title": "BuildIT",
    "text": " Table of Contents BuildIT BuildIT span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } "
},

{
    "id": 35,
    "uri": "blog/profiles/Tim-Engeleiter.html",
    "menu": "Autoren",
    "title": "Tim Engeleiter",
    "text": " Table of Contents Tim Engeleiter Tim Engeleiter span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } image: "
},

{
    "id": 36,
    "uri": "blog/profiles/Maximilian-Franzke.html",
    "menu": "Autoren",
    "title": "Maximilian Franzke",
    "text": " Table of Contents Maximilian Franzke Links Maximilian Franzke span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } Maximilian ist ein erfahrener Softwarearchitekt und Development Lead des DB UX Design System Core bei der DB Systel GmbH, dem Digitalpartner der Deutschen Bahn AG. Er konzipiert und entwickelt Customer und Enterprise Web Anwendungen, und ist spezialisiert im herausfordernden Umfeld von High Performance Websites und Digitaler Barrierefreiheit. Des Weiteren ist er ein Open-Source Enthusiast und an zahlreichen Web-bezogenen L√∂sungen beteiligt. Links X (formerly known as Twitter) Profile GitHub Profile "
},

{
    "id": 37,
    "uri": "blog/profiles/Carsten-Thurau.html",
    "menu": "Autoren",
    "title": "Carsten Thurau",
    "text": " Table of Contents Carsten Thurau Carsten Thurau span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } "
},

{
    "id": 38,
    "uri": "blog/profiles/Bertram-Fey.html",
    "menu": "Autoren",
    "title": "Bertram Fey",
    "text": " Table of Contents Bertram Fey Bertram Fey span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } "
},

{
    "id": 39,
    "uri": "blog/profiles/Gualter-Barbas-Baptista.html",
    "menu": "Autoren",
    "title": "Gualter Barbas Baptista",
    "text": " Table of Contents Gualter Barbas Baptista Gualter Barbas Baptista span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } "
},

{
    "id": 40,
    "uri": "lunrjsindex.html",
    "menu": "null",
    "title": "null",
    "text": " will be replaced by the index "
},

];
